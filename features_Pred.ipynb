{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from antropy import lziv_complexity\n",
    "import multiprocessing as mp\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "import numpy as np\n",
    "import argparse\n",
    "import mne.io\n",
    "import random\n",
    "import mne\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import neurokit2 as nk\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy.signal import hilbert\n",
    "from scipy.fftpack import rfft, irfft\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(trial, epochs):\n",
    "    Lyaps = []\n",
    "    Dims = []\n",
    "    Ent = []\n",
    "    LZC = []\n",
    "    KDF = []\n",
    "\n",
    "    nr_channels =  epochs.shape[1]\n",
    "    trial_data = epochs[trial]\n",
    "\n",
    "    for ch in range(nr_channels):\n",
    "        channel_data = trial_data[ch]\n",
    "        lle, _ = nk.complexity_lyapunov(channel_data, method=\"rosenstein1993\", show=False)\n",
    "        Lyaps.append(lle)\n",
    "\n",
    "        dims, _ = nk.complexity_dimension(channel_data)\n",
    "        Dims.append(dims)\n",
    "\n",
    "        ent, _ = nk.entropy_multiscale(channel_data, show=False, dimension=dims)\n",
    "        Ent.append(ent)\n",
    "\n",
    "        lzc, _ = nk.complexity_lempelziv(channel_data, show=False)\n",
    "        LZC.append(lzc)\n",
    "\n",
    "        kdf, _ = nk.fractal_katz(channel_data)\n",
    "        KDF.append(kdf)\n",
    "\n",
    "    print('Done Trial {}'.format(str(trial)))\n",
    "\n",
    "    return Lyaps, Dims, Ent, LZC, KDF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Lyapunov Exponenf of data/input/10s/sub0-day1-jhana-epo.fif\n",
      "Reading /Users/jonasmago/PhD_code_data/github/Criticality_PCI_Anesthesia/data/input/10s/sub0-day1-jhana-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    9996.09 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "100 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "Interpolating bad channels.\n",
      "    Automatic origin fit: head of radius 95.7 mm\n",
      "Computing interpolation matrix from 30 sensor positions\n",
      "Interpolating 2 sensors\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/hl737msd54q59fzf7spf0r7h0000gn/T/ipykernel_50356/1925645566.py:48: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  epochs = epochs_mne.get_data()\n",
      "/var/folders/bq/hl737msd54q59fzf7spf0r7h0000gn/T/ipykernel_50356/1925645566.py:54: RuntimeWarning: filter_length (8449) is longer than the signal (2560), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs_filt = epochs_mne.filter(lfreq, hfreq, verbose = False)\n",
      "/var/folders/bq/hl737msd54q59fzf7spf0r7h0000gn/T/ipykernel_50356/1925645566.py:58: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  epochs = epochs_filt.get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Trial 8\n",
      "Done Trial 4\n",
      "Done Trial 11\n",
      "Done Trial 7\n",
      "Done Trial 5\n",
      "Done Trial 6\n",
      "Done Trial 3\n",
      "Done Trial 0\n",
      "Done Trial 2\n",
      "Done Trial 10\n",
      "Done Trial 1\n",
      "Done Trial 9\n",
      "Done Trial 12\n",
      "Done Trial 14\n",
      "Done Trial 13\n",
      "Done Trial 16\n",
      "Done Trial 15\n",
      "Done Trial 22\n",
      "Done Trial 18\n",
      "Done Trial 17\n",
      "Done Trial 20\n",
      "Done Trial 21\n",
      "Done Trial 19\n",
      "Done Trial 23\n",
      "Done Trial 26\n",
      "Done Trial 24\n",
      "Done Trial 25\n",
      "Done Trial 27\n",
      "Done Trial 28\n",
      "Done Trial 29\n",
      "Analyzing Lyapunov Exponenf of data/input/10s/sub0-day1-mindfulness-epo.fif\n",
      "Reading /Users/jonasmago/PhD_code_data/github/Criticality_PCI_Anesthesia/data/input/10s/sub0-day1-mindfulness-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    9996.09 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "120 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/hl737msd54q59fzf7spf0r7h0000gn/T/ipykernel_50356/1925645566.py:45: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  epochs_mne.interpolate_bads(reset_bads=True)\n",
      "/var/folders/bq/hl737msd54q59fzf7spf0r7h0000gn/T/ipykernel_50356/1925645566.py:48: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  epochs = epochs_mne.get_data()\n",
      "/var/folders/bq/hl737msd54q59fzf7spf0r7h0000gn/T/ipykernel_50356/1925645566.py:54: RuntimeWarning: filter_length (8449) is longer than the signal (2560), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs_filt = epochs_mne.filter(lfreq, hfreq, verbose = False)\n",
      "/var/folders/bq/hl737msd54q59fzf7spf0r7h0000gn/T/ipykernel_50356/1925645566.py:58: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  epochs = epochs_filt.get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Trial 3\n",
      "Done Trial 6\n",
      "Done Trial 1\n",
      "Done Trial 10\n",
      "Done Trial 4\n",
      "Done Trial 7\n",
      "Done Trial 9\n",
      "Done Trial 8\n",
      "Done Trial 2\n",
      "Done Trial 5\n",
      "Done Trial 0\n",
      "Done Trial 11\n",
      "Done Trial 19\n",
      "Done Trial 16\n",
      "Done Trial 12\n",
      "Done Trial 15\n",
      "Done Trial 14\n",
      "Done Trial 18\n",
      "Done Trial 21\n",
      "Done Trial 22\n",
      "Done Trial 23\n",
      "Done Trial 20\n",
      "Done Trial 17\n",
      "Done Trial 13\n",
      "Done Trial 27\n",
      "Done Trial 25\n",
      "Done Trial 29\n",
      "Done Trial 26\n",
      "Done Trial 24\n",
      "Done Trial 28\n"
     ]
    }
   ],
   "source": [
    "out_dir = 'data/output/Pred/'\n",
    "in_dir = 'data/input/10s/'\n",
    "lfreq = 0.1\n",
    "hfreq = 40\n",
    "\n",
    "# output\n",
    "Lyaps_max = []\n",
    "Lyaps_space = []\n",
    "Dims_mean = []\n",
    "Dims_space = []\n",
    "Ent_mean = []\n",
    "Ent_space = []\n",
    "LZC_mean = []\n",
    "LZC_space = []\n",
    "KDF_mean = []\n",
    "KDF_space = []\n",
    "\n",
    "sub_all = []\n",
    "day_all = []   \n",
    "condition_all = []\n",
    "\n",
    "\n",
    "\n",
    "# make output directory\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "paths = glob.glob(in_dir + '*.fif')\n",
    "paths.sort()\n",
    "paths = paths[:2]\n",
    "\n",
    "#loop over all conditions and particiants\n",
    "for i, path in enumerate(paths):\n",
    "    sub = os.path.basename(path)[:4]\n",
    "    day = os.path.basename(path)[5:9]\n",
    "    condition = os.path.basename(path)[10:-8]\n",
    "\n",
    "    print(f\"Analyzing Lyapunov Exponenf of {path}\");\n",
    "\n",
    "    #################################\n",
    "    #          LOAD  DATA          #\n",
    "    #################################\n",
    "\n",
    "    epochs_mne = mne.read_epochs(path, preload=True)\n",
    "    epochs_mne.interpolate_bads(reset_bads=True)\n",
    "    epochs_mne.pick_types(eeg=True, meg=False, stim=False, eog=False, ecg=False, emg=False, misc=False, exclude='bads')\n",
    "\n",
    "    epochs = epochs_mne.get_data()\n",
    "    fs = 256 #check this\n",
    "\n",
    "\n",
    "    # prepare data\n",
    "    #epochs_res = epochs_mne.resample(250)\n",
    "    epochs_filt = epochs_mne.filter(lfreq, hfreq, verbose = False)\n",
    "\n",
    "    # if data is too long only use the first 3 min of data\n",
    "    nr_trials = min([len(epochs_filt),30])\n",
    "    epochs = epochs_filt.get_data()\n",
    "    nr_channels =  epochs.shape[1]\n",
    "\n",
    "    #################################\n",
    "    #    Calculate LZC             #\n",
    "    #################################\n",
    "\n",
    "    # Run parallel processing for all trials\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(get_pred)(trial, epochs) for trial in range(nr_trials)\n",
    "    )\n",
    "\n",
    "    # Convert results to NumPy array\n",
    "    results = np.array(results)\n",
    "\n",
    "    # Compute summary statistics\n",
    "    Lyaps_max.append(np.mean(results[:, 0, :], axis=(0, 1)))\n",
    "    Lyaps_space.append(np.mean(results[:, 0, :], axis=0))\n",
    "    Dims_mean.append(np.mean(results[:, 1, :], axis=(0, 1)))\n",
    "    Dims_space.append(np.mean(results[:, 1, :], axis=0))\n",
    "    Ent_mean.append(np.mean(results[:, 2, :], axis=(0, 1)))\n",
    "    Ent_space.append(np.mean(results[:, 2, :], axis=0))\n",
    "    LZC_mean.append(np.mean(results[:, 3, :], axis=(0, 1)))\n",
    "    LZC_space.append(np.mean(results[:, 3, :], axis=0))\n",
    "    KDF_mean.append(np.mean(results[:, 4, :], axis=(0, 1)))\n",
    "    KDF_space.append(np.mean(results[:, 4, :], axis=0))\n",
    "    sub_all.append(sub)\n",
    "    day_all.append(day)\n",
    "    condition_all.append(condition)\n",
    "\n",
    "\n",
    "    # save part\n",
    "    output_df = {'sub':sub_all, 'day': day_all,'condition':condition_all,\n",
    "                'Lyaps_max':Lyaps_max, 'Dims_mean':Dims_mean,\n",
    "                'Ent_mean':Ent_mean, 'LZC_mean':LZC_mean,'KDF_mean':KDF_mean }\n",
    "    output_df = pd.DataFrame(output_df)\n",
    "    output_df.to_csv(f'{out_dir}/Pred_{lfreq}_{hfreq}.csv', index=False, sep=',')\n",
    "\n",
    "    # save space\n",
    "    output_df_space = {'sub':sub_all, 'day': day_all,'condition':condition_all}\n",
    "    output_df = pd.concat((pd.DataFrame(output_df_space), pd.DataFrame(Lyaps_space).reset_index(drop=True)), axis = 1)\n",
    "    output_df.to_csv(f'{out_dir}/Lyaps_space_{lfreq}_{hfreq}.csv', index=False, sep=',')\n",
    "\n",
    "    # save space\n",
    "    output_df_space = {'sub':sub_all, 'day': day_all,'condition':condition_all}\n",
    "    output_df = pd.concat((pd.DataFrame(output_df_space), pd.DataFrame(Dims_space).reset_index(drop=True)), axis = 1)\n",
    "    output_df.to_csv(f'{out_dir}/Dims_space_{lfreq}_{hfreq}.csv', index=False, sep=',')\n",
    "\n",
    "    # save space\n",
    "    output_df_space = {'sub':sub_all, 'day': day_all,'condition':condition_all}\n",
    "    output_df = pd.concat((pd.DataFrame(output_df_space), pd.DataFrame(Ent_space).reset_index(drop=True)), axis = 1)\n",
    "    output_df.to_csv(f'{out_dir}/Ent_space_{lfreq}_{hfreq}.csv', index=False, sep=',')\n",
    "\n",
    "    # save space\n",
    "    output_df_space = {'sub':sub_all, 'day': day_all,'condition':condition_all}\n",
    "    output_df = pd.concat((pd.DataFrame(output_df_space), pd.DataFrame(LZC_space).reset_index(drop=True)), axis = 1)\n",
    "    output_df.to_csv(f'{out_dir}/LZC_space_{lfreq}_{hfreq}.csv', index=False, sep=',')\n",
    "\n",
    "    # save space\n",
    "    output_df_space = {'sub':sub_all, 'day': day_all,'condition':condition_all}\n",
    "    output_df = pd.concat((pd.DataFrame(output_df_space), pd.DataFrame(KDF_space).reset_index(drop=True)), axis = 1)\n",
    "    output_df.to_csv(f'{out_dir}/KDF_space_{lfreq}_{hfreq}.csv', index=False, sep=',')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
