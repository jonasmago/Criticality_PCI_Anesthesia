{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import welch\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "from mne.time_frequency import psd_array_multitaper, psd_array_welch\n",
    "from fooof import FOOOF\n",
    "import numpy as np\n",
    "import argparse\n",
    "import mne.io\n",
    "import mne\n",
    "import os\n",
    "import neurokit2 as nk\n",
    "import multiprocessing as mp\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "import glob\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call:  python features_DFA.py -data_dir EPOCHS -output_dir RESULTS -part_info EPOCHS/participants.txt -lfrequ 8 -hfrequ 14\n",
    "\n",
    "def get_channel_hurst(ch_data,sfreq):\n",
    "\n",
    "    scale = nk.expspace(1*sfreq, 20*sfreq, 40, base=2).astype(np.int64)\n",
    "\n",
    "    analytic_signal = hilbert(ch_data)\n",
    "    amplitude_envelope = np.abs(analytic_signal)\n",
    "\n",
    "    try:\n",
    "        hurst_fh, _ = nk.fractal_hurst(amplitude_envelope, scale=scale, show=False)\n",
    "    except:\n",
    "        hurst_fh = float('nan')\n",
    "\n",
    "    try:\n",
    "        hurst_dfa, _ = nk.fractal_dfa(amplitude_envelope, scale=scale, show=False)\n",
    "    except:\n",
    "        hurst_dfa = float('nan')\n",
    "\n",
    "    return  hurst_fh, hurst_dfa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing DFA of data/input/continuous/sub0-day2-jhana-raw.fif\n",
      "Opening raw data file data/input/continuous/sub0-day2-jhana-raw.fif...\n",
      "    Range : 512 ... 323799 =      2.000 ...  1264.840 secs\n",
      "Ready.\n",
      "Reading 0 ... 323287  =      0.000 ...  1262.840 secs...\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "Interpolating bad channels.\n",
      "    Automatic origin fit: head of radius 95.7 mm\n",
      "Computing interpolation matrix from 29 sensor positions\n",
      "Interpolating 3 sensors\n",
      "Analyzing DFA of data/input/continuous/sub0-day2-mindfulness-raw.fif\n",
      "Opening raw data file data/input/continuous/sub0-day2-mindfulness-raw.fif...\n",
      "    Range : 512 ... 294535 =      2.000 ...  1150.527 secs\n",
      "Ready.\n",
      "Reading 0 ... 294023  =      0.000 ...  1148.527 secs...\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "Interpolating bad channels.\n",
      "    Automatic origin fit: head of radius 95.7 mm\n",
      "Computing interpolation matrix from 23 sensor positions\n",
      "Interpolating 9 sensors\n",
      "Processing complete. Results saved.\n"
     ]
    }
   ],
   "source": [
    "# Define input and output directories\n",
    "out_dir = 'data/output/DFA/'\n",
    "in_dir = 'data/input/continuous/'\n",
    "lfreq = 0.1  # Low frequency filter\n",
    "hfreq = 40   # High frequency filter\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# Find all .fif files\n",
    "paths = glob.glob(in_dir + '*.fif')\n",
    "paths.sort()\n",
    "paths = paths[2:4]  # Adjust file selection if needed\n",
    "\n",
    "# Lists to store results\n",
    "HURST_FH = []\n",
    "HURST_DFA = []\n",
    "sub_ids = []\n",
    "days = []\n",
    "conditions = []\n",
    "\n",
    "# Extract metadata from filenames\n",
    "def extract_metadata(path):\n",
    "    filename = os.path.basename(path)  # Extract filename\n",
    "    parts = filename.split('-')  # Assuming a naming convention like \"subX-dayY-conditionZ.fif\"\n",
    "    sub = parts[0]  # Example: \"sub0\"\n",
    "    day = parts[1]  # Example: \"day2\"\n",
    "    condition = parts[2].split('.')[0]  # Example: \"jhana\" (removing \".fif\")\n",
    "    return sub, day, condition\n",
    "\n",
    "# Loop over each file\n",
    "for path in paths:\n",
    "    print(f\"Analyzing DFA of {path}\")\n",
    "\n",
    "    # Extract metadata\n",
    "    sub, day, condition = extract_metadata(path)\n",
    "    sub_ids.append(sub)\n",
    "    days.append(day)\n",
    "    conditions.append(condition)\n",
    "\n",
    "    # Load data\n",
    "    raw = mne.io.read_raw_fif(path, preload=True)\n",
    "    raw.interpolate_bads(reset_bads=True)\n",
    "    data = raw.get_data()[0:32, :]  # Use only first 32 channels\n",
    "    fs = 256  # Sampling frequency\n",
    "    sig_length = min(data.shape[1] / fs, 200)  # Ensure max 200s of data\n",
    "    nr_channels = data.shape[0]  # Number of channels\n",
    "\n",
    "    # Cut data\n",
    "    cut = int(sig_length * fs)\n",
    "    data = data[:, :cut]\n",
    "\n",
    "    # Apply filtering\n",
    "    data_filt = mne.filter.filter_data(data, sfreq=fs, l_freq=lfreq, h_freq=hfreq, verbose=False)\n",
    "\n",
    "    # Run multiprocessing using joblib\n",
    "    results = Parallel(n_jobs=-1)(delayed(get_channel_hurst)(data_filt[ch, :], fs) for ch in range(nr_channels))\n",
    "\n",
    "    # Store results\n",
    "    HURST_FH.append(np.mean(pd.DataFrame(results)[0]))\n",
    "    HURST_DFA.append(np.mean(pd.DataFrame(results)[1]))\n",
    "\n",
    "# Save results with metadata\n",
    "output_df = pd.DataFrame({\n",
    "    'sub': sub_ids,\n",
    "    'day': days,\n",
    "    'condition': conditions,\n",
    "    'HURST_FH': HURST_FH,\n",
    "    'HURST_DFA': HURST_DFA\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "output_df.to_csv(f'{out_dir}/DFA_{lfreq}_{hfreq}.csv', index=False, sep=',')\n",
    "\n",
    "print(\"Processing complete. Results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
